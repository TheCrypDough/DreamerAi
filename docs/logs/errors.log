# Ensure a newline at the end if the file might be empty or just created
[2024-04-09 18:21:15] - Error Occurred: Day 1 setup script execution interrupted. Task: Day 1 Initial Project Setup & Refined Configuration. Status: Halted.
[2024-04-09 18:40:05] - Error Occurred: Failed to create batch file 'C:\DreamerAI\create_dirs.bat' due to invalid path error (EINVAL). Task: Day 1 Initial Project Setup & Refined Configuration. Status: Retrying file creation.
[2025-04-10 21:23:45] - Error Identified: FastAPI server failed to start via `python -m engine.core.server`. Error: `ERROR:    Error loading ASGI app. Could not import module "server".`. Task: Day 5: SQLite Database & Basic UI Bridge, Status: Investigating.
[2025-04-10 21:23:45] - Error Resolved: FastAPI server failed to load module via `python -m`. Task: Day 5: SQLite Database & Basic UI Bridge, Fix: Started server successfully using `uvicorn engine.core.server:app --reload` directly from the project root directory.
[2025-04-11 02:40:00] - Error Resolved: TypeError: DreamerLogger.__init__() got an unexpected keyword argument 'name', Task: Day 7 - Execute Nexus Test Block, Fix: Corrected nexus.py logger init.
[2025-04-11 02:45:00] - Error Resolved: ValueError: "Nexus" object has no field "llm", Task: Day 7 - Execute Nexus Test Block, Fix: Added 'llm' field to Nexus class.
[2025-04-11 02:52:00] - Error Resolved: ValidationError: 1 validation error for Nexus llm Field required, Task: Day 7 - Execute Nexus Test Block, Fix: Corrected Nexus.__init__ super() call.
[2025-04-11 02:58:00] - Error Resolved: AttributeError: type object 'AgentState' has no attribute 'PROCESSING', Task: Day 7 - Execute Nexus Test Block, Fix: Corrected AgentState reference.
[2025-04-11 03:05:00] - Error Resolved: TypeError: LLM.generate() got an unexpected keyword argument 'config', Task: Day 7 - Execute Nexus Test Block, Fix: Corrected LLM.generate() arguments.

# DreamerAI Critical Errors Log

[2025-04-11 04:34:00] - Error Identified: `AttributeError: 'Client' object has no attribute 'persist'`. Task: Day 8.2 Seed Jeff RAG DB. Script: `scripts/seed_rag_jeff.py`. Reason: ChromaDB API change.
[2025-04-11 04:35:00] - Error Resolved: `AttributeError: 'Client' object has no attribute 'persist'`. Task: Day 8.2. Fix: Removed `client.persist()` call.

[2025-04-11 05:05:00] - Error Identified: `pydantic_core._pydantic_core.ValidationError: 1 validation error for ChefJeff user_dir Input should be a valid string`. Task: Day 8.4 Test ChefJeff Class. Script: `engine/agents/main_chat.py` (test block). Reason: `BaseAgent.user_dir` type hint was `str`, not `Optional[str]`.
[2025-04-11 05:06:00] - Error Resolved: `ValidationError` on `ChefJeff` init (`user_dir`). Task: Day 8.4. Fix: Modified `BaseAgent` to use `Optional[str]` for `user_dir`.

[2025-04-11 05:10:00] - Error Identified: `ValueError: "ChefJeff" object has no field "rules"`. Task: Day 8.4 Test ChefJeff Class. Script: `engine/agents/main_chat.py` (test block). Reason: `rules` assigned in `__init__` after `super()`.
[2025-04-11 05:12:00] - Error Resolved: `ValueError` on `ChefJeff` init (field assignment). Task: Day 8.4. Fix: Defined `rules` and other fields as class attributes using `pydantic.Field`.

[2025-04-11 05:15:00] - Error Identified: `chromadb.errors.NotFoundError: Collection [jeff_context] does not exists`. Task: Day 8.4 Test ChefJeff Class. Script: `engine/agents/main_chat.py` (test block). Reason: Used `get_collection` instead of `get_or_create_collection`.
[2025-04-11 05:18:00] - Error Resolved: `NotFoundError` on ChromaDB get_collection. Task: Day 8.4. Fix: Changed to `get_or_create_collection`.

[2025-04-11 05:15:00] - Error Identified: `pydantic_core._pydantic_core.ValidationError: 1 validation error for Message role Field required`. Task: Day 8.4 Test ChefJeff Class. Script: `engine/agents/main_chat.py` (test block - initial message). Reason: Used `sender="User"` instead of `role="user"`.
[2025-04-11 05:18:00] - Error Resolved: `ValidationError` on `Message` init. Task: Day 8.4. Fix: Changed to `role="user"`.

[2025-04-11 05:22:00] - Error Identified: `AttributeError: 'Memory' object has no attribute 'get_formatted_history'`. Task: Day 8.4 Test ChefJeff Class. Script: `engine/agents/main_chat.py` (test block - step method). Reason: Incorrect method name used.
[2025-04-11 05:28:00] - Error Resolved: `AttributeError: 'Memory' object has no attribute 'get_formatted_history'`. Task: Day 8.4. Fix: Changed call to `get_history()` in `step` method (via reapply).

[2025-04-11 05:30:00] - Error Identified: `TypeError: Memory.get_history() got an unexpected keyword argument 'last_n'`. Task: Day 8.4 Test ChefJeff Class. Script: `engine/agents/main_chat.py` (test block - step method). Reason: `get_history` does not accept `last_n`.
[2025-04-11 05:31:00] - Error Resolved: `TypeError` on `Memory.get_history` call. Task: Day 8.4. Fix: Removed `last_n=5` argument.

[2025-04-11 05:41:47] - Error Identified: `AttributeError: 'ChefJeff' object has no attribute 'llm'`. Task: Day 8.4 Test ChefJeff Class. Script: `engine/agents/main_chat.py` (test block - step method). Reason: Incorrect assignment/validation order of `llm` instance in `__init__`.
[2025-04-11 05:41:47] - Error Identified: `pydantic_core._pydantic_core.ValidationError: 1 validation error for Message role Field required`. Task: Day 8.4 Test ChefJeff Class. Script: `engine/agents/main_chat.py` (test block - except block). Reason: Used `sender="Jeff"` instead of `role="assistant"`.
[2025-04-11 05:46:00] - Error Resolved: `AttributeError: 'ChefJeff' object has no attribute 'llm'` & `ValidationError` on error Message init. Task: Day 8.4. Fix: Passed `llm=llm_instance` in `super().__init__` call and corrected error `Message` instantiation to use `role="assistant"`.

[2025-04-11 05:50:00] - Error Identified: `AttributeError: 'Memory' object has no attribute 'get_formatted_history'`. Task: Day 8.4 Test ChefJeff Class. Script: `engine/agents/main_chat.py` (test block - final print). Reason: Incorrect method name used.
[2025-04-11 05:55:00] - Error Resolved: `AttributeError` in test block print statement. Task: Day 8.4. Fix: Changed `jeff.memory.get_formatted_history()` to `jeff.memory.get_history()`.

# --- Content from errors_2025-04-10.log ---
2025-04-10 19:35:02 | ERROR    | __main__:<module>:89 - This is an error message.
2025-04-10 19:35:02 | ERROR    | __main__:<module>:94 - Caught an exception!
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
> File "C:\DreamerAI\engine\core\logger.py", line 92, in <module>
    1 / 0
ZeroDivisionError: division by zero
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
> File "C:\DreamerAI\engine\core\logger.py", line 92, in <module>
    1 / 0
ZeroDivisionError: division by zero
2025-04-10 21:02:21 | ERROR    | __main__:<module>:89 - This is an error message.
2025-04-10 21:02:21 | ERROR    | __main__:<module>:94 - Caught an exception!
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
> File "C:\DreamerAI\engine\core\logger.py", line 92, in <module>
    1 / 0
ZeroDivisionError: division by zero
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
> File "C:\DreamerAI\engine\core\logger.py", line 92, in <module>
    1 / 0
ZeroDivisionError: division by zero
2025-04-10 21:54:31 | ERROR    | __main__:generate:283 - All configured providers failed to generate a response: ['ollama', 'cloud_tier1', 'cloud_tier2']
2025-04-10 21:54:31 | ERROR    | __main__:run_tests:306 - Test 1 Failed (Default)
2025-04-10 21:54:31 | ERROR    | __main__:generate:283 - All configured providers failed to generate a response: ['cloud_tier1', 'ollama', 'cloud_tier2']
2025-04-10 21:54:31 | ERROR    | __main__:run_tests:313 - Test 2 Failed (Jeff Override - maybe override not configured or provider failed?)
2025-04-10 21:54:31 | ERROR    | __main__:generate:283 - All configured providers failed to generate a response: ['ollama', 'cloud_tier1', 'cloud_tier2']
2025-04-10 21:54:31 | ERROR    | __main__:run_tests:320 - Test 3 Failed (Ziggy Default)
2025-04-10 21:55:43 | ERROR    | __main__:_generate_openai_compatible:212 - OpenAI API status error for 'cloud_tier1' model llama3-70b-8192: Status=401, Response=<Response [401 Unauthorized]>
2025-04-10 21:55:44 | ERROR    | __main__:_generate_openai_compatible:212 - OpenAI API status error for 'cloud_tier2' model deepseek-chat: Status=401, Response=<Response [401 Unauthorized]>
2025-04-10 21:55:44 | ERROR    | __main__:generate:283 - All configured providers failed to generate a response: ['ollama', 'cloud_tier1', 'cloud_tier2']
2025-04-10 21:55:44 | ERROR    | __main__:run_tests:306 - Test 1 Failed (Default)
2025-04-10 21:55:44 | ERROR    | __main__:_generate_openai_compatible:212 - OpenAI API status error for 'cloud_tier1' model llama3-70b-8192: Status=401, Response=<Response [401 Unauthorized]>
2025-04-10 21:55:45 | ERROR    | __main__:_generate_openai_compatible:212 - OpenAI API status error for 'cloud_tier2' model deepseek-chat: Status=401, Response=<Response [401 Unauthorized]>
2025-04-10 21:55:45 | ERROR    | __main__:generate:283 - All configured providers failed to generate a response: ['cloud_tier1', 'ollama', 'cloud_tier2']
2025-04-10 21:55:45 | ERROR    | __main__:run_tests:313 - Test 2 Failed (Jeff Override - maybe override not configured or provider failed?)
2025-04-10 21:55:45 | ERROR    | __main__:_generate_openai_compatible:212 - OpenAI API status error for 'cloud_tier1' model llama3-70b-8192: Status=401, Response=<Response [401 Unauthorized]>
2025-04-10 21:55:45 | ERROR    | __main__:_generate_openai_compatible:212 - OpenAI API status error for 'cloud_tier2' model deepseek-chat: Status=401, Response=<Response [401 Unauthorized]>
2025-04-10 21:55:45 | ERROR    | __main__:generate:283 - All configured providers failed to generate a response: ['ollama', 'cloud_tier1', 'cloud_tier2']
2025-04-10 21:55:45 | ERROR    | __main__:run_tests:320 - Test 3 Failed (Ziggy Default)
2025-04-10 23:06:09 | ERROR    | __main__:_generate_openai_compatible:190 - OpenAI compatible client 'openrouter_cloud' not initialized or found.
2025-04-10 23:06:09 | ERROR    | __main__:generate:284 - All configured providers failed to generate a response: ['openrouter_cloud', 'ollama']
2025-04-10 23:06:09 | ERROR    | __main__:run_tests:307 - Test 1 Failed (Default)
2025-04-10 23:06:09 | ERROR    | __main__:_generate_openai_compatible:190 - OpenAI compatible client 'openrouter_cloud' not initialized or found.
2025-04-10 23:06:09 | ERROR    | __main__:generate:284 - All configured providers failed to generate a response: ['openrouter_cloud', 'ollama']
2025-04-10 23:06:09 | ERROR    | __main__:run_tests:314 - Test 2 Failed (Jeff Override - maybe override not configured or provider failed?)
2025-04-10 23:06:09 | ERROR    | __main__:_generate_openai_compatible:190 - OpenAI compatible client 'openrouter_cloud' not initialized or found.
2025-04-10 23:06:09 | ERROR    | __main__:generate:284 - All configured providers failed to generate a response: ['openrouter_cloud', 'ollama']
2025-04-10 23:06:09 | ERROR    | __main__:run_tests:321 - Test 3 Failed (Ziggy Default)
2025-04-10 23:10:03 | ERROR    | __main__:_generate_openai_compatible:190 - OpenAI compatible client 'openrouter_cloud' not initialized or found.
2025-04-10 23:10:03 | ERROR    | __main__:generate:284 - All configured providers failed to generate a response: ['openrouter_cloud', 'ollama']
2025-04-10 23:10:03 | ERROR    | __main__:run_tests:307 - Test 1 Failed (Default)
2025-04-10 23:10:03 | ERROR    | __main__:_generate_openai_compatible:190 - OpenAI compatible client 'openrouter_cloud' not initialized or found.
2025-04-10 23:10:03 | ERROR    | __main__:generate:284 - All configured providers failed to generate a response: ['openrouter_cloud', 'ollama']
2025-04-10 23:10:03 | ERROR    | __main__:run_tests:314 - Test 2 Failed (Jeff Override - maybe override not configured or provider failed?)
2025-04-10 23:10:03 | ERROR    | __main__:_generate_openai_compatible:190 - OpenAI compatible client 'openrouter_cloud' not initialized or found.
2025-04-10 23:10:03 | ERROR    | __main__:generate:284 - All configured providers failed to generate a response: ['openrouter_cloud', 'ollama']
2025-04-10 23:10:03 | ERROR    | __main__:run_tests:321 - Test 3 Failed (Ziggy Default)
2025-04-10 23:13:24 | ERROR    | __main__:_generate_openai_compatible:213 - OpenAI API status error for 'openrouter_cloud' model meta-llama/Llama-3-70b-chat-hf: Status=400, Response=<Response [400 Bad Request]>
2025-04-10 23:13:24 | ERROR    | __main__:generate:284 - All configured providers failed to generate a response: ['openrouter_cloud', 'ollama']
2025-04-10 23:13:24 | ERROR    | __main__:run_tests:307 - Test 1 Failed (Default)
2025-04-10 23:13:24 | ERROR    | __main__:_generate_openai_compatible:213 - OpenAI API status error for 'openrouter_cloud' model meta-llama/Llama-3-70b-chat-hf: Status=400, Response=<Response [400 Bad Request]>
2025-04-10 23:13:24 | ERROR    | __main__:generate:284 - All configured providers failed to generate a response: ['openrouter_cloud', 'ollama']
2025-04-10 23:13:24 | ERROR    | __main__:run_tests:314 - Test 2 Failed (Jeff Override - maybe override not configured or provider failed?)
2025-04-10 23:13:24 | ERROR    | __main__:_generate_openai_compatible:213 - OpenAI API status error for 'openrouter_cloud' model meta-llama/Llama-3-70b-chat-hf: Status=400, Response=<Response [400 Bad Request]>
2025-04-10 23:13:24 | ERROR    | __main__:generate:284 - All configured providers failed to generate a response: ['openrouter_cloud', 'ollama']
2025-04-10 23:13:24 | ERROR    | __main__:run_tests:321 - Test 3 Failed (Ziggy Default)

# --- Content from errors_2025-04-11.log ---
2025-04-11 00:08:56 | ERROR    | __main__:_generate_openai_compatible:213 - OpenAI API status error for 'openrouter_cloud' model meta-llama/Llama-3-70b-chat-hf: Status=400, Response=<Response [400 Bad Request]>
2025-04-11 00:08:56 | ERROR    | __main__:generate:284 - All configured providers failed to generate a response: ['openrouter_cloud', 'ollama']
2025-04-11 00:08:56 | ERROR    | __main__:run_tests:307 - Test 1 Failed (Default)
2025-04-11 00:08:56 | ERROR    | __main__:_generate_openai_compatible:213 - OpenAI API status error for 'openrouter_cloud' model meta-llama/Llama-3-70b-chat-hf: Status=400, Response=<Response [400 Bad Request]>
2025-04-11 00:08:56 | ERROR    | __main__:generate:284 - All configured providers failed to generate a response: ['openrouter_cloud', 'ollama']
2025-04-11 00:08:56 | ERROR    | __main__:run_tests:314 - Test 2 Failed (Jeff Override - maybe override not configured or provider failed?)
2025-04-11 00:08:56 | ERROR    | __main__:_generate_openai_compatible:213 - OpenAI API status error for 'openrouter_cloud' model meta-llama/Llama-3-70b-chat-hf: Status=400, Response=<Response [400 Bad Request]>
2025-04-11 00:08:56 | ERROR    | __main__:generate:284 - All configured providers failed to generate a response: ['openrouter_cloud', 'ollama']
2025-04-11 00:08:56 | ERROR    | __main__:run_tests:321 - Test 3 Failed (Ziggy Default)
2025-04-11 00:35:24 | ERROR    | __main__:_generate_openai_compatible:190 - OpenAI compatible client 'openrouter_cloud' not initialized or found.
2025-04-11 00:35:24 | ERROR    | __main__:generate:284 - All configured providers failed to generate a response: ['openrouter_cloud', 'ollama']
2025-04-11 00:35:24 | ERROR    | __main__:run_tests:307 - Test 1 Failed (Default)
2025-04-11 00:35:24 | ERROR    | __main__:_generate_openai_compatible:190 - OpenAI compatible client 'openrouter_cloud' not initialized or found.
2025-04-11 00:35:24 | ERROR    | __main__:generate:284 - All configured providers failed to generate a response: ['openrouter_cloud', 'ollama']
2025-04-11 00:35:24 | ERROR    | __main__:run_tests:314 - Test 2 Failed (Jeff Override - maybe override not configured or provider failed?)
2025-04-11 00:35:24 | ERROR    | __main__:_generate_openai_compatible:190 - OpenAI compatible client 'openrouter_cloud' not initialized or found.
2025-04-11 00:35:24 | ERROR    | __main__:generate:284 - All configured providers failed to generate a response: ['openrouter_cloud', 'ollama']
2025-04-11 00:35:24 | ERROR    | __main__:run_tests:321 - Test 3 Failed (Ziggy Default)
2025-04-11 02:39:23 | ERROR    | NexusAgent:step:99 - Error during LLM generation in Nexus step: LLM.generate() got an unexpected keyword argument 'config'
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "C:\DreamerAI\engine\ai\nexus.py", line 165, in <module>
    asyncio.run(main())
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\runners.py", line 195, in run
    return runner.run(main)
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 706, in run_until_complete
    self.run_forever()
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 677, in run_forever
    self._run_once()
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 2034, in _run_once
    handle._run()
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)
  File "C:\DreamerAI\engine\ai\nexus.py", line 154, in main
    result = await nexus_agent.run(test_prompt)
  File "C:\DreamerAI\engine\ai\nexus.py", line 119, in run
    result = await self.step(input_data)
> File "C:\DreamerAI\engine\ai\nexus.py", line 94, in step
    response = await self.llm.generate(prompt, config=generation_config)
TypeError: LLM.generate() got an unexpected keyword argument 'config'
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "C:\DreamerAI\engine\ai\nexus.py", line 165, in <module>
    asyncio.run(main())
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\runners.py", line 195, in run
    return runner.run(main)
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 706, in run_until_complete
    self.run_forever()
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 677, in run_forever
    self._run_once()
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 2034, in _run_once
    handle._run()
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)
  File "C:\DreamerAI\engine\ai\nexus.py", line 154, in main
    result = await nexus_agent.run(test_prompt)
  File "C:\DreamerAI\engine\ai\nexus.py", line 119, in run
    result = await self.step(input_data)
> File "C:\DreamerAI\engine\ai\nexus.py", line 94, in step
    response = await self.llm.generate(prompt, config=generation_config)
TypeError: LLM.generate() got an unexpected keyword argument 'config'
2025-04-11 04:37:04 | ERROR    | __main__:_initialize_rag:97 - Failed to initialize ChromaDB or load embedding model: Collection [jeff_context] does not exists
Traceback (most recent call last):
  File "C:\DreamerAI\engine\agents\main_chat.py", line 89, in _initialize_rag
    self.rag_collection = self.rag_client.get_collection(name=collection_name)
  File "C:\DreamerAI\venv\Lib\site-packages\chromadb\api\client.py", line 178, in get_collection
    model = self._server.get_collection(
  File "C:\DreamerAI\venv\Lib\site-packages\chromadb\api\rust.py", line 246, in get_collection
    collection = self.bindings.get_collection(name, tenant, database)
chromadb.errors.NotFoundError: Collection [jeff_context] does not exists
2025-04-11 04:41:47 | ERROR    | __main__:step:176 - LLM generation failed for Jeff: 'ChefJeff' object has no attribute 'llm'
Traceback (most recent call last):
  File "C:\DreamerAI\engine\agents\main_chat.py", line 162, in step
    logger.info(f"Calling LLM (provider for 'Jeff': {self.llm.get_provider_for_agent('Jeff')})")
  File "C:\DreamerAI\venv\Lib\site-packages\pydantic\main.py", line 994, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
AttributeError: 'ChefJeff' object has no attribute 'llm'

# Append errors from 2025-04-12
2025-04-12 00:05:30 | ERROR    | __main__:run_dreamer_flow:65 - Failed to initialize agents: engine.agents.base.BaseAgent.__init__() got multiple values for keyword argument 'user_dir'
Traceback (most recent call last):

  File "C:\DreamerAI\main.py", line 111, in <module>
    asyncio.run(run_dreamer_flow())
    │       │   └ <function run_dreamer_flow at 0x0000025218C51440>
    │       └ <function run at 0x000002521B0A63E0>
    └ <module 'asyncio' from 'C:\\Users\\thecr\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\__init__.py'>

  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\runners.py", line 195, in run
    return runner.run(main)
           │      │   └ <coroutine object run_dreamer_flow at 0x000002521B0D9EA0>
           │      └ <function Runner.run at 0x000002521B13C900>
           └ <asyncio.runners.Runner object at 0x000002520CE5DA90>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           │    │     │                  └ <Task pending name='Task-1' coro=<run_dreamer_flow() running at C:\DreamerAI\main.py:65> cb=[_run_until_complete_cb() at C:\U...
           │    │     └ <function BaseEventLoop.run_until_complete at 0x000002521B13A480>
           │    └ <ProactorEventLoop running=True closed=False debug=False>
           └ <asyncio.runners.Runner object at 0x000002520CE5DA90>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 706, in run_until_complete
    self.run_forever()
    │    └ <function BaseEventLoop.run_forever at 0x000002521B13A3E0>
    └ <ProactorEventLoop running=True closed=False debug=False>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 677, in run_forever
    self._run_once()
    │    └ <function BaseEventLoop._run_once at 0x000002521B13C220>
    └ <ProactorEventLoop running=True closed=False debug=False>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 2034, in _run_once
    handle._run()
    │      └ <function Handle._run at 0x000002521AC4AFC0>
    └ <Handle <_asyncio.TaskStepMethWrapper object at 0x000002520C32EDD0>()>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)
    │    │            │    │           │    └ <member '_args' of 'Handle' objects>
    │    │            │    │           └ <Handle <_asyncio.TaskStepMethWrapper object at 0x000002520C32EDD0>()>
    │    │            │    └ <member '_callback' of 'Handle' objects>
    │    │            └ <Handle <_asyncio.TaskStepMethWrapper object at 0x000002520C32EDD0>()>
    │    └ <member '_context' of 'Handle' objects>
    └ <Handle <_asyncio.TaskStepMethWrapper object at 0x000002520C32EDD0>()>

> File "C:\DreamerAI\main.py", line 53, in run_dreamer_flow
    agents["Jeff"] = ChefJeff(llm_instance=llm_service, user_dir=DEFAULT_USER_DIR)
    │                │                     │                     └ 'C:\\DreamerAI\\Users\\Example User'
    │                │                     └ <engine.ai.llm.LLM object at 0x000002520CE5E120>
    │                └ <class 'engine.agents.main_chat.ChefJeff'>
    └ {}

  File "C:\DreamerAI\engine\agents\main_chat.py", line 61, in __init__
    super().__init__(name="Jeff", user_dir=data.get("user_dir"), distill=False, llm=llm_instance, **data)
                                           │    │                                   │               └ {'user_dir': 'C:\\DreamerAI\\Users\\Example User'}
                                           │    │                                   └ <engine.ai.llm.LLM object at 0x000002520CE5E120>
                                           │    └ <method 'get' of 'dict' objects>
                                           └ {'user_dir': 'C:\\DreamerAI\\Users\\Example User'}

TypeError: engine.agents.base.BaseAgent.__init__() got multiple values for keyword argument 'user_dir'

Traceback (most recent call last):

  File "C:\DreamerAI\main.py", line 111, in <module>
    asyncio.run(run_dreamer_flow())
    │       │   └ <function run_dreamer_flow at 0x0000025218C51440>
    │       └ <function run at 0x000002521B0A63E0>
    └ <module 'asyncio' from 'C:\\Users\\thecr\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\__init__.py'>

  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\runners.py", line 195, in run
    return runner.run(main)
           │      │   └ <coroutine object run_dreamer_flow at 0x000002521B0D9EA0>
           │      └ <function Runner.run at 0x000002521B13C900>
           └ <asyncio.runners.Runner object at 0x000002520CE5DA90>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           │    │     │                  └ <Task pending name='Task-1' coro=<run_dreamer_flow() running at C:\DreamerAI\main.py:65> cb=[_run_until_complete_cb() at C:\U...
           │    │     └ <function BaseEventLoop.run_until_complete at 0x000002521B13A480>
           │    └ <ProactorEventLoop running=True closed=False debug=False>
           └ <asyncio.runners.Runner object at 0x000002520CE5DA90>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 706, in run_until_complete
    self.run_forever()
    │    └ <function BaseEventLoop.run_forever at 0x000002521B13A3E0>
    └ <ProactorEventLoop running=True closed=False debug=False>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 677, in run_forever
    self._run_once()
    │    └ <function BaseEventLoop._run_once at 0x000002521B13C220>
    └ <ProactorEventLoop running=True closed=False debug=False>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 2034, in _run_once
    handle._run()
    │      └ <function Handle._run at 0x000002521AC4AFC0>
    └ <Handle <_asyncio.TaskStepMethWrapper object at 0x000002520C32EDD0>()>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)
    │    │            │    │           │    └ <member '_args' of 'Handle' objects>
    │    │            │    │           └ <Handle <_asyncio.TaskStepMethWrapper object at 0x000002520C32EDD0>()>
    │    │            │    └ <member '_callback' of 'Handle' objects>
    │    │            └ <Handle <_asyncio.TaskStepMethWrapper object at 0x000002520C32EDD0>()>
    │    └ <member '_context' of 'Handle' objects>
    └ <Handle <_asyncio.TaskStepMethWrapper object at 0x000002520C32EDD0>()>

  File "C:\DreamerAI\main.py", line 53, in run_dreamer_flow
    agents["Jeff"] = ChefJeff(llm_instance=llm_service, user_dir=DEFAULT_USER_DIR)
    │                │                     │                     └ 'C:\\DreamerAI\\Users\\Example User'
    │                │                     └ <engine.ai.llm.LLM object at 0x000002520CE5E120>
    │                └ <class 'engine.agents.main_chat.ChefJeff'>
    └ {}

  File "C:\DreamerAI\engine\agents\main_chat.py", line 61, in __init__
    super().__init__(name="Jeff", user_dir=data.get("user_dir"), distill=False, llm=llm_instance, **data)
                                           │    │                                   │               └ {'user_dir': 'C:\\DreamerAI\\Users\\Example User'}
                                           │    │                                   └ <engine.ai.llm.LLM object at 0x000002520CE5E120>
                                           │    └ <method 'get' of 'dict' objects>
                                           └ {'user_dir': 'C:\\DreamerAI\\Users\\Example User'}

TypeError: engine.agents.base.BaseAgent.__init__() got multiple values for keyword argument 'user_dir'

Traceback (most recent call last):

  File "C:\DreamerAI\main.py", line 111, in <module>
    asyncio.run(run_dreamer_flow())
    │       │   └ <function run_dreamer_flow at 0x0000025218C51440>
    │       └ <function run at 0x000002521B0A63E0>
    └ <module 'asyncio' from 'C:\\Users\\thecr\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\__init__.py'>

  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\runners.py", line 195, in run
    return runner.run(main)
           │      │   └ <coroutine object run_dreamer_flow at 0x000002521B0D9EA0>
           │      └ <function Runner.run at 0x000002521B13C900>
           └ <asyncio.runners.Runner object at 0x000002520CE5DA90>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           │    │     │                  └ <Task pending name='Task-1' coro=<run_dreamer_flow() running at C:\DreamerAI\main.py:65> cb=[_run_until_complete_cb() at C:\U...
           │    │     └ <function BaseEventLoop.run_until_complete at 0x000002521B13A480>
           │    └ <ProactorEventLoop running=True closed=False debug=False>
           └ <asyncio.runners.Runner object at 0x000002520CE5DA90>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 706, in run_until_complete
    self.run_forever()
    │    └ <function BaseEventLoop.run_forever at 0x000002521B13A3E0>
    └ <ProactorEventLoop running=True closed=False debug=False>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 677, in run_forever
    self._run_once()
    │    └ <function BaseEventLoop._run_once at 0x000002521B13C220>
    └ <ProactorEventLoop running=True closed=False debug=False>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 2034, in _run_once
    handle._run()
    │      └ <function Handle._run at 0x000002521AC4AFC0>
    └ <Handle <_asyncio.TaskStepMethWrapper object at 0x000002520C32EDD0>()>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)
    │    │            │    │           │    └ <member '_args' of 'Handle' objects>
    │    │            │    │           └ <Handle <_asyncio.TaskStepMethWrapper object at 0x000002520C32EDD0>()>
    │    │            │    └ <member '_callback' of 'Handle' objects>
    │    │            └ <Handle <_asyncio.TaskStepMethWrapper object at 0x000002520C32EDD0>()>
    │    └ <member '_context' of 'Handle' objects>
    └ <Handle <_asyncio.TaskStepMethWrapper object at 0x000002520C32EDD0>()>

  File "C:\DreamerAI\main.py", line 53, in run_dreamer_flow
    agents["Jeff"] = ChefJeff(llm_instance=llm_service, user_dir=DEFAULT_USER_DIR)
    │                │                     │                     └ 'C:\\DreamerAI\\Users\\Example User'
    │                │                     └ <engine.ai.llm.LLM object at 0x000002520CE5E120>
    │                └ <class 'engine.agents.main_chat.ChefJeff'>
    └ {}

  File "C:\DreamerAI\engine\agents\main_chat.py", line 61, in __init__
    super().__init__(name="Jeff", user_dir=data.get("user_dir"), distill=False, llm=llm_instance, **data)
                                           │    │                                   │               └ {'user_dir': 'C:\\DreamerAI\\Users\\Example User'}
                                           │    │                                   └ <engine.ai.llm.LLM object at 0x000002520CE5E120>
                                           │    └ <method 'get' of 'dict' objects>
                                           └ {'user_dir': 'C:\\DreamerAI\\Users\\Example User'}

TypeError: engine.agents.base.BaseAgent.__init__() got multiple values for keyword argument 'user_dir'

2025-04-12 00:06:01 | ERROR    | engine.core.workflow:execute:112 - An unexpected error occurred during DreamerFlow execution: ChefJeff.run() got an unexpected keyword argument 'initial_user_input'. Did you mean 'initial_input'?
Traceback (most recent call last):

  File "C:\DreamerAI\main.py", line 111, in <module>
    asyncio.run(run_dreamer_flow())
    │       │   └ <function run_dreamer_flow at 0x000001A1B16C1440>
    │       └ <function run at 0x000001A1B3B163E0>
    └ <module 'asyncio' from 'C:\\Users\\thecr\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\__init__.py'>

  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\runners.py", line 195, in run
    return runner.run(main)
           │      │   └ <coroutine object run_dreamer_flow at 0x000001A1B3B49EA0>
           │      └ <function Runner.run at 0x000001A1B3BAC900>
           └ <asyncio.runners.Runner object at 0x000001A1A5BADA90>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           │    │     │                  └ <Task pending name='Task-1' coro=<run_dreamer_flow() running at C:\DreamerAI\main.py:90> cb=[_run_until_complete_cb() at C:\U...
           │    │     └ <function BaseEventLoop.run_until_complete at 0x000001A1B3BAA480>
           │    └ <ProactorEventLoop running=True closed=False debug=False>
           └ <asyncio.runners.Runner object at 0x000001A1A5BADA90>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 706, in run_until_complete
    self.run_forever()
    │    └ <function BaseEventLoop.run_forever at 0x000001A1B3BAA3E0>
    └ <ProactorEventLoop running=True closed=False debug=False>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 677, in run_forever
    self._run_once()
    │    └ <function BaseEventLoop._run_once at 0x000001A1B3BAC220>
    └ <ProactorEventLoop running=True closed=False debug=False>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 2034, in _run_once
    handle._run()
    │      └ <function Handle._run at 0x000001A1B36BAFC0>
    └ <Handle <_asyncio.TaskStepMethWrapper object at 0x000001A1A5B68C70>()>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)
    │    │            │    │           │    └ <member '_args' of 'Handle' objects>
    │    │            │    │           └ <Handle <_asyncio.TaskStepMethWrapper object at 0x000001A1A5B68C70>()>
    │    │            │    └ <member '_callback' of 'Handle' objects>
    │    │            └ <Handle <_asyncio.TaskStepMethWrapper object at 0x000001A1A5B68C70>()>
    │    └ <member '_context' of 'Handle' objects>
    └ <Handle <_asyncio.TaskStepMethWrapper object at 0x000001A1A5B68C70>()>

  File "C:\DreamerAI\main.py", line 90, in run_dreamer_flow
    result = await dreamer_flow.execute(initial_user_input=test_input)
                   │            │                          └ "Hi Jeff, let's plan a simple website."
                   │            └ <function DreamerFlow.execute at 0x000001A1A5C74900>
                   └ <engine.core.workflow.DreamerFlow object at 0x000001A1A7060D70>

> File "C:\DreamerAI\engine\core\workflow.py", line 86, in execute
    jeff_response = await jeff_agent.run(initial_user_input=initial_user_input) # Changed from guide's user_input to match local var
                          │          │                      └ "Hi Jeff, let's plan a simple website."
                          │          └ <function ChefJeff.run at 0x000001A1A5C74400>
                          └ ChefJeff(name='Jeff', user_dir='C:\\DreamerAI\\Users\\Example User', state='idle', memory=Memory(messages=[], max_history=50)...

TypeError: ChefJeff.run() got an unexpected keyword argument 'initial_user_input'. Did you mean 'initial_input'?

Traceback (most recent call last):

  File "C:\DreamerAI\main.py", line 111, in <module>
    asyncio.run(run_dreamer_flow())
    │       │   └ <function run_dreamer_flow at 0x000001A1B16C1440>
    │       └ <function run at 0x000001A1B3B163E0>
    └ <module 'asyncio' from 'C:\\Users\\thecr\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\asyncio\\__init__.py'>

  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\runners.py", line 195, in run
    return runner.run(main)
           │      │   └ <coroutine object run_dreamer_flow at 0x000001A1B3B49EA0>
           │      └ <function Runner.run at 0x000001A1B3BAC900>
           └ <asyncio.runners.Runner object at 0x000001A1A5BADA90>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           │    │     │                  └ <Task pending name='Task-1' coro=<run_dreamer_flow() running at C:\DreamerAI\main.py:90> cb=[_run_until_complete_cb() at C:\U...
           │    │     └ <function BaseEventLoop.run_until_complete at 0x000001A1B3BAA480>
           │    └ <ProactorEventLoop running=True closed=False debug=False>
           └ <asyncio.runners.Runner object at 0x000001A1A5BADA90>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 706, in run_until_complete
    self.run_forever()
    │    └ <function BaseEventLoop.run_forever at 0x000001A1B3BAA3E0>
    └ <ProactorEventLoop running=True closed=False debug=False>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 677, in run_forever
    self._run_once()
    │    └ <function BaseEventLoop._run_once at 0x000001A1B3BAC220>
    └ <ProactorEventLoop running=True closed=False debug=False>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\base_events.py", line 2034, in _run_once
    handle._run()
    │      └ <function Handle._run at 0x000001A1B36BAFC0>
    └ <Handle <_asyncio.TaskStepMethWrapper object at 0x000001A1A5B68C70>()>
  File "C:\Users\thecr\AppData\Local\Programs\Python\Python313\Lib\asyncio\events.py", line 89, in _run
    self._context.run(self._callback, *self._args)
    │    │            │    │           │    └ <member '_args' of 'Handle' objects>
    │    │            │    │           └ <Handle <_asyncio.TaskStepMethWrapper object at 0x000001A1A5B68C70>()>
    │    │            │    └ <member '_callback' of 'Handle' objects>
    │    │            └ <Handle <_asyncio.TaskStepMethWrapper object at 0x000001A1A5B68C70>()>
    │    └ <member '_context' of 'Handle' objects>
    └ <Handle <_asyncio.TaskStepMethWrapper object at 0x000001A1A5B68C70>()>

  File "C:\DreamerAI\main.py", line 90, in run_dreamer_flow
    result = await dreamer_flow.execute(initial_user_input=test_input)
                   │            │                          └ "Hi Jeff, let's plan a simple website."
                   │            └ <function DreamerFlow.execute at 0x000001A1A5C74900>
                   └ <engine.core.workflow.DreamerFlow object at 0x000001A1A7060D70>

> File "C:\DreamerAI\engine\core\workflow.py", line 86, in execute
    jeff_response = await jeff_agent.run(initial_user_input=initial_user_input) # Changed from guide's user_input to match local var
                          │          │                      └ "Hi Jeff, let's plan a simple website."
                          │          └ <function ChefJeff.run at 0x000001A1A5C74400>
                          └ ChefJeff(name='Jeff', user_dir='C:\\DreamerAI\\Users\\Example User', state='idle', memory=Memory(messages=[], max_history=50)...

TypeError: ChefJeff.run() got an unexpected keyword argument 'initial_user_input'. Did you mean 'initial_input'?
